{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "md-title",
   "metadata": {},
   "source": [
    "# GNN-DRE + Label Shift Correction (LSC) Binary WCP\n",
    "\n",
    "**Extends**: `gnn_dre_wcp.ipynb`  \n",
    "**Methods compared** (all at α = 0.10):\n",
    "\n",
    "| Method | Covariate shift | Label shift | Notes |\n",
    "|--------|----------------|-------------|-------|\n",
    "| **Std CP** | ✗ | ✗ | Baseline |\n",
    "| **WCP-GNN** | GNN-DRE (ESS≈31%) | ✗ | From gnn_dre_wcp_report |\n",
    "| **WCP-GNN+EM-LSC** | GNN-DRE (ESS≈31%) | EM-estimated NIH prior | **New** |\n",
    "| **WCP-GNN+Oracle-LSC** | GNN-DRE (ESS≈31%) | True NIH prior | Upper bound |\n",
    "\n",
    "**Core research question**: Does correcting for label shift (via Bayesian odds-ratio adjustment)\n",
    "reduce the dangerously high singleton FNR (up to 99.2% for Pneumothorax) observed in WCP-GNN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "ROOT = Path('../..').resolve()\n",
    "if str(ROOT / 'src') not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT / 'src'))\n",
    "\n",
    "from wcp_l2d.dre import AdaptiveDRE\n",
    "from wcp_l2d.features import ExtractedFeatures\n",
    "from wcp_l2d.gnn import build_adjacency_matrix, train_gnn\n",
    "from wcp_l2d.pathologies import COMMON_PATHOLOGIES\n",
    "from wcp_l2d.conformal import ConformalPredictor, WeightedConformalPredictor\n",
    "from wcp_l2d.evaluation import evaluate_standard_cp, evaluate_wcp\n",
    "\n",
    "SEED   = 42\n",
    "ALPHA  = 0.10          # 90 % coverage target\n",
    "EXPERT = 0.85\n",
    "K      = len(COMMON_PATHOLOGIES)\n",
    "DEVICE = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "plt.rcParams.update({'figure.dpi': 100, 'figure.facecolor': 'white',\n",
    "                     'axes.grid': True, 'grid.alpha': 0.3})\n",
    "print(f'Device:      {DEVICE}')\n",
    "print(f'Pathologies: {COMMON_PATHOLOGIES}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-s1",
   "metadata": {},
   "source": [
    "## 1. Load Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-load",
   "metadata": {},
   "outputs": [],
   "source": [
    "FEAT_DIR = ROOT / 'data' / 'features'\n",
    "chex = ExtractedFeatures.load(FEAT_DIR / 'chexpert_densenet121-res224-chex_features.npz')\n",
    "nih  = ExtractedFeatures.load(FEAT_DIR / 'nih_densenet121-res224-chex_features.npz')\n",
    "\n",
    "print(f'CheXpert: {chex.features.shape}  labels: {chex.labels.shape}')\n",
    "print(f'NIH:      {nih.features.shape}   labels: {nih.labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-s2",
   "metadata": {},
   "source": [
    "## 2. Global Data Splits\n",
    "\n",
    "Identical splits to `gnn_dre_wcp.ipynb` (same `SEED=42`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-splits",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(SEED)\n",
    "\n",
    "# --- CheXpert: 60 % train / 20 % cal / 20 % ignored ---\n",
    "N_chex = len(chex.features)\n",
    "idx    = rng.permutation(N_chex)\n",
    "n_tr   = int(0.60 * N_chex)\n",
    "n_cal  = int(0.20 * N_chex)\n",
    "\n",
    "X_train_raw = chex.features[idx[:n_tr]]\n",
    "Y_train     = chex.labels[idx[:n_tr]]\n",
    "X_cal_raw   = chex.features[idx[n_tr:n_tr + n_cal]]\n",
    "Y_cal       = chex.labels[idx[n_tr:n_tr + n_cal]]\n",
    "\n",
    "# --- NIH: 50 % DRE pool / 50 % labelled test ---\n",
    "N_nih    = len(nih.features)\n",
    "nih_perm = rng.permutation(N_nih)\n",
    "n_pool   = N_nih // 2\n",
    "\n",
    "X_pool_raw = nih.features[nih_perm[:n_pool]]\n",
    "X_nih_raw  = nih.features[nih_perm[n_pool:]]\n",
    "Y_nih_test = nih.labels[nih_perm[n_pool:]]\n",
    "\n",
    "# StandardScaler fitted on train set\n",
    "scaler  = StandardScaler().fit(X_train_raw)\n",
    "X_train = scaler.transform(X_train_raw)\n",
    "X_cal   = scaler.transform(X_cal_raw)\n",
    "X_pool  = scaler.transform(X_pool_raw)\n",
    "X_nih   = scaler.transform(X_nih_raw)\n",
    "\n",
    "print(f'CheXpert  train={len(X_train):,}  cal={len(X_cal):,}')\n",
    "print(f'NIH       pool={len(X_pool):,}    test={len(X_nih):,}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-s3",
   "metadata": {},
   "source": [
    "## 3. Build 7×7 Label Co-occurrence Adjacency Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-adj",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = build_adjacency_matrix(Y_train, tau=0.10)\n",
    "assert torch.allclose(A.sum(dim=1), torch.ones(K), atol=1e-5), 'Row sums must equal 1'\n",
    "print(f'Adjacency matrix built. Shape: {A.shape}')\n",
    "n_nonzero = int((A > 0).sum()) - K\n",
    "print(f'Non-zero off-diagonal entries: {n_nonzero} / {K*(K-1)} ({100*n_nonzero/(K*(K-1)):.0f}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-s4",
   "metadata": {},
   "source": [
    "## 4. Train Binary LR Classifiers (GNN Residual Init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lrs",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = []\n",
    "for k, path in enumerate(COMMON_PATHOLOGIES):\n",
    "    valid = ~np.isnan(Y_train[:, k])\n",
    "    if valid.sum() < 10 or len(np.unique(Y_train[valid, k])) < 2:\n",
    "        lrs.append(None)\n",
    "        continue\n",
    "    lr = LogisticRegression(solver='lbfgs', max_iter=1000, random_state=SEED)\n",
    "    lr.fit(X_train[valid], Y_train[valid, k].astype(int))\n",
    "    lrs.append(lr)\n",
    "\n",
    "def get_logits_lr(lrs_, X_s):\n",
    "    \"\"\"[N, K] decision function from 7 binary LRs.\"\"\"\n",
    "    out = np.zeros((len(X_s), K), dtype=np.float32)\n",
    "    for k, lr in enumerate(lrs_):\n",
    "        if lr is not None:\n",
    "            out[:, k] = lr.decision_function(X_s)\n",
    "    return out\n",
    "\n",
    "init_tr   = get_logits_lr(lrs, X_train)\n",
    "init_cal  = get_logits_lr(lrs, X_cal)\n",
    "init_pool = get_logits_lr(lrs, X_pool)\n",
    "init_nih  = get_logits_lr(lrs, X_nih)\n",
    "print('LR classifiers trained.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-s5",
   "metadata": {},
   "source": [
    "## 5. Train LabelGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-gnn-train",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Training LabelGCN on {DEVICE} (50 epochs) ...')\n",
    "\n",
    "gnn, history = train_gnn(\n",
    "    features_train=X_train,\n",
    "    labels_train=Y_train,\n",
    "    features_val=X_cal,\n",
    "    labels_val=Y_cal,\n",
    "    adjacency=A,\n",
    "    init_logits_train=init_tr,\n",
    "    init_logits_val=init_cal,\n",
    "    epochs=50,\n",
    "    save_best=True,\n",
    "    batch_size=512,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4,\n",
    "    device=DEVICE,\n",
    "    verbose=False,\n",
    ")\n",
    "\n",
    "best_ep = history['best_epoch'][0]\n",
    "print(f'Best val AUC: {max(history[\"val_auc\"]):.4f}  at epoch {best_ep}/50')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-s6",
   "metadata": {},
   "source": [
    "## 6. GNN Probability Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-gnn-probs",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gnn_probs(model, X_s, init_np=None):\n",
    "    \"\"\"Forward pass → sigmoid probabilities [N, K].\"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        Xt = torch.tensor(X_s, dtype=torch.float32)\n",
    "        it = torch.tensor(init_np, dtype=torch.float32) if init_np is not None else None\n",
    "        logits = model(Xt, it).numpy()\n",
    "    return 1.0 / (1.0 + np.exp(-logits))\n",
    "\n",
    "p_train = gnn_probs(gnn, X_train, init_tr)\n",
    "p_cal   = gnn_probs(gnn, X_cal,   init_cal)\n",
    "p_pool  = gnn_probs(gnn, X_pool,  init_pool)\n",
    "p_nih   = gnn_probs(gnn, X_nih,   init_nih)\n",
    "\n",
    "print(f'GNN probs: p_cal={p_cal.shape}  p_pool={p_pool.shape}  p_nih={p_nih.shape}')\n",
    "\n",
    "# Per-pathology AUC on NIH test\n",
    "rows = []\n",
    "for k, path in enumerate(COMMON_PATHOLOGIES):\n",
    "    valid = ~np.isnan(Y_nih_test[:, k])\n",
    "    if valid.sum() < 2 or len(np.unique(Y_nih_test[valid, k])) < 2:\n",
    "        rows.append({'Pathology': path, 'GNN AUC': float('nan')}); continue\n",
    "    y = Y_nih_test[valid, k]\n",
    "    rows.append({'Pathology': path, 'GNN AUC': round(roc_auc_score(y, p_nih[valid, k]), 4)})\n",
    "\n",
    "auc_df = pd.DataFrame(rows).set_index('Pathology')\n",
    "print(f'\\nNIH GNN AUC (mean={auc_df[\"GNN AUC\"].mean():.4f}):')\n",
    "print(auc_df.T.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-s7",
   "metadata": {},
   "source": [
    "## 7. GNN-DRE\n",
    "\n",
    "Source = CheXpert calibration set (GNN probability space).  \n",
    "Target = NIH unlabelled pool (GNN probability space).  \n",
    "No PCA, no clipping — identical to `gnn_dre_wcp.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-dre",
   "metadata": {},
   "outputs": [],
   "source": [
    "dre_gnn = AdaptiveDRE(n_components=None, weight_clip=None, random_state=SEED)\n",
    "dre_gnn.fit(source_features=p_cal, target_features=p_pool)\n",
    "w_cal_gnn = dre_gnn.compute_weights(p_cal)\n",
    "w_nih_gnn = dre_gnn.compute_weights(p_nih)\n",
    "diag_gnn  = dre_gnn.diagnostics(p_cal)\n",
    "\n",
    "print('=== GNN-DRE Diagnostics (CheXpert cal set) ===')\n",
    "print(f'  Domain AUC : {diag_gnn.domain_auc:.4f}')\n",
    "print(f'  ESS        : {diag_gnn.ess:.1f}  ({diag_gnn.ess_fraction*100:.1f}%)')\n",
    "print(f'  Weight mean: {diag_gnn.weight_mean:.3f}  median: {diag_gnn.weight_median:.3f}  max: {diag_gnn.weight_max:.3f}')\n",
    "\n",
    "# Per-pathology ESS\n",
    "ess_rows = []\n",
    "for k, path in enumerate(COMMON_PATHOLOGIES):\n",
    "    c_mask = ~np.isnan(Y_cal[:, k])\n",
    "    wc = w_cal_gnn[c_mask]\n",
    "    ess_k = float(wc.sum()**2 / (wc**2).sum()) / c_mask.sum()\n",
    "    ess_rows.append({'Pathology': path, 'n_cal': int(c_mask.sum()), 'ESS%': round(ess_k*100, 1)})\n",
    "print('\\nPer-pathology ESS on filtered cal subset:')\n",
    "print(pd.DataFrame(ess_rows).set_index('Pathology').T.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-s8",
   "metadata": {},
   "source": [
    "## 8. Label Shift Correction (LSC)\n",
    "\n",
    "### Motivation\n",
    "\n",
    "WCP-GNN addresses covariate shift but not label shift.  Under label shift, the class prior\n",
    "changes between domains: CheXpert has higher disease prevalence than NIH (e.g. Pneumothorax\n",
    "6.7% vs 0.9%).  The binary LR classifier trained on CheXpert is therefore biased toward\n",
    "predicting positive, causing high FNR on NIH singleton decisions.\n",
    "\n",
    "**LSC** applies a Bayesian odds-ratio correction:\n",
    "$$\n",
    "\\tilde{p}(y=1|x) = \\sigma\\!\\left(\\log\\text{odds}_{\\text{src}}(x) + \\log\\frac{\\pi_{\\text{tgt}}/(1-\\pi_{\\text{tgt}})}{\\pi_{\\text{src}}/(1-\\pi_{\\text{src}})}\\right)\n",
    "$$\n",
    "where $\\text{odds}_{\\text{src}}(x) = p_{\\text{src}}(y=1|x)/(1-p_{\\text{src}}(y=1|x))$ is the\n",
    "source-domain model's odds, and $\\pi_{\\text{src}},\\pi_{\\text{tgt}}$ are the source and target\n",
    "class priors.\n",
    "\n",
    "### EM Algorithm (Unsupervised)\n",
    "\n",
    "The target prior $\\pi_{\\text{tgt}}$ is estimated without labels using Expectation-Maximisation\n",
    "on the GNN probability outputs on the NIH test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lsc-funcs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================================================\n",
    "# LSC helper functions (provided in experiment spec)\n",
    "# =====================================================\n",
    "\n",
    "def estimate_target_prior_em(gnn_probs_tgt, prior_src, max_iters=100, tol=1e-5):\n",
    "    \"\"\"\n",
    "    EM algorithm to estimate target domain prevalence from unlabelled data.\n",
    "    Treats each of the K pathologies as an independent binary classification task.\n",
    "\n",
    "    Args:\n",
    "        gnn_probs_tgt : [N, K]  GNN probabilities on NIH test\n",
    "        prior_src     : [K]     CheXpert train prevalences\n",
    "        max_iters, tol          convergence control\n",
    "    Returns:\n",
    "        estimated_prior_tgt : [K]  estimated NIH prevalences\n",
    "    \"\"\"\n",
    "    N, K = gnn_probs_tgt.shape\n",
    "    eps = 1e-7\n",
    "\n",
    "    prior_tgt_current  = np.clip(np.copy(prior_src), eps, 1 - eps)\n",
    "    prior_src_clipped  = np.clip(prior_src, eps, 1 - eps)\n",
    "    probs_clipped      = np.clip(gnn_probs_tgt, eps, 1 - eps)\n",
    "\n",
    "    for i in range(max_iters):\n",
    "        # E-step: Bayes-adjust current probs to current tgt prior\n",
    "        odds_ratio    = (prior_tgt_current / (1 - prior_tgt_current)) / \\\n",
    "                        (prior_src_clipped  / (1 - prior_src_clipped))\n",
    "        odds_src      = probs_clipped / (1 - probs_clipped)\n",
    "        odds_tgt      = odds_src * odds_ratio\n",
    "        adjusted_probs = odds_tgt / (1 + odds_tgt)\n",
    "\n",
    "        # M-step: update prior estimate\n",
    "        prior_tgt_new = np.mean(adjusted_probs, axis=0)\n",
    "\n",
    "        if np.max(np.abs(prior_tgt_new - prior_tgt_current)) < tol:\n",
    "            print(f'  EM converged at iteration {i+1}')\n",
    "            prior_tgt_current = prior_tgt_new\n",
    "            break\n",
    "        prior_tgt_current = prior_tgt_new\n",
    "\n",
    "    return prior_tgt_current\n",
    "\n",
    "\n",
    "def apply_label_shift_correction(gnn_probs, prior_src, prior_tgt):\n",
    "    \"\"\"\n",
    "    Bayesian odds-ratio correction.\n",
    "    Works on [N, K] matrices (K pathologies in parallel).\n",
    "    \"\"\"\n",
    "    eps = 1e-7\n",
    "    prior_src  = np.clip(prior_src,  eps, 1 - eps)\n",
    "    prior_tgt  = np.clip(prior_tgt,  eps, 1 - eps)\n",
    "    gnn_probs  = np.clip(gnn_probs,  eps, 1 - eps)\n",
    "\n",
    "    odds_ratio = (prior_tgt / (1 - prior_tgt)) / (prior_src / (1 - prior_src))\n",
    "    odds_src   = gnn_probs  / (1 - gnn_probs)\n",
    "    odds_tgt   = odds_src * odds_ratio\n",
    "    return odds_tgt / (1 + odds_tgt)\n",
    "\n",
    "\n",
    "def corrected_binary_logits(clf, X, prior_src_k, prior_tgt_k, eps=1e-7):\n",
    "    \"\"\"\n",
    "    Apply per-pathology LSC to binary LR probabilities and return binary logits.\n",
    "    Binary logits: [-d, d] where d = log-odds of corrected P(y=1|x).\n",
    "    \"\"\"\n",
    "    probs = np.clip(clf.predict_proba(X)[:, 1], eps, 1 - eps)          # [N]\n",
    "    prior_s = np.clip(prior_src_k, eps, 1 - eps)\n",
    "    prior_t = np.clip(prior_tgt_k, eps, 1 - eps)\n",
    "\n",
    "    odds_ratio = (prior_t / (1 - prior_t)) / (prior_s / (1 - prior_s))\n",
    "    adj_odds   = (probs / (1 - probs)) * odds_ratio\n",
    "    adj_probs  = np.clip(adj_odds / (1 + adj_odds), eps, 1 - eps)\n",
    "\n",
    "    logits = np.log(adj_probs) - np.log(1 - adj_probs)                 # log-odds\n",
    "    return np.column_stack([-logits, logits])                           # [N, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-lsc-priors",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Source prior from CheXpert train ---\n",
    "prior_src = np.nanmean(Y_train, axis=0)      # [K]\n",
    "\n",
    "# --- Oracle target prior (true NIH test prevalence) ---\n",
    "prior_tgt_oracle = np.nanmean(Y_nih_test, axis=0)  # [K]\n",
    "\n",
    "# --- EM-estimated target prior (unsupervised, runs on NIH test GNN probs) ---\n",
    "print('Running EM on NIH test GNN probabilities ...')\n",
    "prior_tgt_em = estimate_target_prior_em(p_nih, prior_src)\n",
    "\n",
    "# --- Comparison table ---\n",
    "df_priors = pd.DataFrame({\n",
    "    'CheXpert (src)':    np.round(prior_src, 4),\n",
    "    'NIH oracle':        np.round(prior_tgt_oracle, 4),\n",
    "    'NIH EM-estimated':  np.round(prior_tgt_em, 4),\n",
    "    'EM error (pp)':     np.round((prior_tgt_em - prior_tgt_oracle) * 100, 2),\n",
    "    'Odds ratio (EM/src)': np.round(\n",
    "        (np.clip(prior_tgt_em, 1e-7, 1-1e-7) / (1 - np.clip(prior_tgt_em, 1e-7, 1-1e-7))) /\n",
    "        (np.clip(prior_src,   1e-7, 1-1e-7) / (1 - np.clip(prior_src,   1e-7, 1-1e-7))),\n",
    "        4),\n",
    "}, index=COMMON_PATHOLOGIES)\n",
    "print('\\nPrevalence comparison:')\n",
    "print(df_priors.to_string())\n",
    "print('\\n(Odds ratio < 1 = model needs to predict LESS positive in target)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-s9",
   "metadata": {},
   "source": [
    "## 9. Per-Pathology Binary WCP — Four Methods\n",
    "\n",
    "For each pathology:\n",
    "1. Filter cal / NIH-test to non-NaN rows for that pathology.\n",
    "2. Train per-pathology binary LR on filtered train set.\n",
    "3. Compute binary RAPS logits — both raw (no LSC) and LSC-corrected variants.\n",
    "4. Run all four methods across α ∈ [0.01, 0.50].\n",
    "\n",
    "> **Note on LSC application**: LSC is applied to *both* calibration and test LR probabilities\n",
    "> so that RAPS scores are computed from the same (target-recalibrated) score function.\n",
    "> This ensures calibration and test scores live on the same scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-per-path",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = np.linspace(0.01, 0.50, 50)\n",
    "\n",
    "def binary_logits_from_lr(clf, X):\n",
    "    \"\"\"Standard binary logits from LR decision function.\"\"\"\n",
    "    d = clf.decision_function(X)\n",
    "    return np.column_stack([-d, d])\n",
    "\n",
    "def at_alpha(res_list, a=ALPHA):\n",
    "    return min(res_list, key=lambda r: abs(r.alpha_or_threshold - a))\n",
    "\n",
    "all_results = {}\n",
    "clfs_per_path = {}   # cache classifiers for later analysis\n",
    "\n",
    "for pathology in COMMON_PATHOLOGIES:\n",
    "    k = COMMON_PATHOLOGIES.index(pathology)\n",
    "\n",
    "    c_mask = ~np.isnan(Y_cal[:, k])\n",
    "    n_mask = ~np.isnan(Y_nih_test[:, k])\n",
    "    Xc, yc = X_cal[c_mask],  Y_cal[c_mask, k].astype(int)\n",
    "    Xn, yn = X_nih[n_mask],  Y_nih_test[n_mask, k].astype(int)\n",
    "\n",
    "    # Per-pathology binary LR\n",
    "    tr_mask = ~np.isnan(Y_train[:, k])\n",
    "    clf_p   = LogisticRegression(solver='lbfgs', max_iter=1000, C=1.0, random_state=SEED)\n",
    "    clf_p.fit(X_train[tr_mask], Y_train[tr_mask, k].astype(int))\n",
    "    clfs_per_path[pathology] = (clf_p, c_mask, n_mask, yc, yn)\n",
    "\n",
    "    # Logits — raw and LSC-corrected\n",
    "    cal_lg        = binary_logits_from_lr(clf_p, Xc)\n",
    "    nih_lg        = binary_logits_from_lr(clf_p, Xn)\n",
    "    cal_lg_em     = corrected_binary_logits(clf_p, Xc, prior_src[k], prior_tgt_em[k])\n",
    "    nih_lg_em     = corrected_binary_logits(clf_p, Xn, prior_src[k], prior_tgt_em[k])\n",
    "    cal_lg_oracle = corrected_binary_logits(clf_p, Xc, prior_src[k], prior_tgt_oracle[k])\n",
    "    nih_lg_oracle = corrected_binary_logits(clf_p, Xn, prior_src[k], prior_tgt_oracle[k])\n",
    "\n",
    "    # DRE weights\n",
    "    wc_gnn = w_cal_gnn[c_mask]\n",
    "    wn_gnn = w_nih_gnn[n_mask]\n",
    "\n",
    "    nih_auc = roc_auc_score(yn, clf_p.predict_proba(Xn)[:, 1])\n",
    "\n",
    "    std_cp         = evaluate_standard_cp(cal_lg,        yc, nih_lg,        yn, alphas, expert_accuracy=EXPERT)\n",
    "    wcp_gnn        = evaluate_wcp(cal_lg,        yc, wc_gnn, nih_lg,        yn, wn_gnn, alphas, expert_accuracy=EXPERT)\n",
    "    wcp_gnn_em     = evaluate_wcp(cal_lg_em,     yc, wc_gnn, nih_lg_em,     yn, wn_gnn, alphas, expert_accuracy=EXPERT)\n",
    "    wcp_gnn_oracle = evaluate_wcp(cal_lg_oracle, yc, wc_gnn, nih_lg_oracle, yn, wn_gnn, alphas, expert_accuracy=EXPERT)\n",
    "\n",
    "    all_results[pathology] = {\n",
    "        'std_cp':         std_cp,\n",
    "        'wcp_gnn':        wcp_gnn,\n",
    "        'wcp_gnn_em':     wcp_gnn_em,\n",
    "        'wcp_gnn_oracle': wcp_gnn_oracle,\n",
    "        'nih_auc':        nih_auc,\n",
    "        'n_cal':          int(c_mask.sum()),\n",
    "        'n_nih':          int(n_mask.sum()),\n",
    "        'n_pos':          int(yn.sum()),\n",
    "    }\n",
    "\n",
    "    pt_gnn    = at_alpha(wcp_gnn)\n",
    "    pt_em     = at_alpha(wcp_gnn_em)\n",
    "    pt_oracle = at_alpha(wcp_gnn_oracle)\n",
    "    print(f'{pathology:<16} AUC={nih_auc:.3f}  '\n",
    "          f'GNN={pt_gnn.deferral_rate:.3f}({pt_gnn.coverage_rate:.3f})  '\n",
    "          f'EM-LSC={pt_em.deferral_rate:.3f}({pt_em.coverage_rate:.3f})  '\n",
    "          f'Oracle={pt_oracle.deferral_rate:.3f}({pt_oracle.coverage_rate:.3f})')\n",
    "\n",
    "print('\\n(deferral | coverage)  Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-s10",
   "metadata": {},
   "source": [
    "## 10. Summary Table at α = 0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-table",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for path in COMMON_PATHOLOGIES:\n",
    "    r   = all_results[path]\n",
    "    std = at_alpha(r['std_cp'])\n",
    "    gnn = at_alpha(r['wcp_gnn'])\n",
    "    em  = at_alpha(r['wcp_gnn_em'])\n",
    "    orc = at_alpha(r['wcp_gnn_oracle'])\n",
    "    rows.append({\n",
    "        'Pathology':        path,\n",
    "        'NIH AUC':          f\"{r['nih_auc']:.3f}\",\n",
    "        'Std Defer':        f\"{std.deferral_rate:.3f}\",\n",
    "        'GNN Defer':        f\"{gnn.deferral_rate:.3f}\",\n",
    "        'GNN Cov':          f\"{gnn.coverage_rate:.3f}\",\n",
    "        'EM-LSC Defer':     f\"{em.deferral_rate:.3f}\",\n",
    "        'EM-LSC Cov':       f\"{em.coverage_rate:.3f}\",\n",
    "        'Oracle Defer':     f\"{orc.deferral_rate:.3f}\",\n",
    "        'Oracle Cov':       f\"{orc.coverage_rate:.3f}\",\n",
    "    })\n",
    "\n",
    "df_sum = pd.DataFrame(rows)\n",
    "print(f'LSC Experiment Summary — α={ALPHA}')\n",
    "print('=' * 120)\n",
    "print(df_sum.to_string(index=False))\n",
    "\n",
    "print()\n",
    "for col, key in [('Std Defer','std_cp'), ('GNN Defer','wcp_gnn'),\n",
    "                  ('EM-LSC Defer','wcp_gnn_em'), ('Oracle Defer','wcp_gnn_oracle')]:\n",
    "    mean_d = np.mean([at_alpha(all_results[p][key]).deferral_rate for p in COMMON_PATHOLOGIES])\n",
    "    mean_c = np.mean([at_alpha(all_results[p][key]).coverage_rate  for p in COMMON_PATHOLOGIES])\n",
    "    print(f'  Mean {col:<18}  defer={mean_d:.3f}   coverage={mean_c:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-s11",
   "metadata": {},
   "source": [
    "## 11. Deferral Rate vs Confidence Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-defer-plot",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 4, figsize=(22, 9), sharey=False)\n",
    "axes_flat = axes.flatten()\n",
    "conf_lvls = 1 - alphas\n",
    "\n",
    "METHODS = [\n",
    "    ('Std CP',     'std_cp',         'o-',  '#1f77b4', 1.5),\n",
    "    ('WCP-GNN',    'wcp_gnn',        's-',  '#2ca02c', 1.8),\n",
    "    ('WCP+EM-LSC', 'wcp_gnn_em',     '^-',  '#d62728', 2.0),\n",
    "    ('WCP+Oracle', 'wcp_gnn_oracle', 'D--', '#9467bd', 1.5),\n",
    "]\n",
    "\n",
    "for i, path in enumerate(COMMON_PATHOLOGIES):\n",
    "    ax = axes_flat[i]\n",
    "    r  = all_results[path]\n",
    "    for label, key, style, col, lw in METHODS:\n",
    "        ax.plot(conf_lvls, [x.deferral_rate for x in r[key]],\n",
    "                style, ms=2, lw=lw, alpha=0.85, label=label, color=col)\n",
    "    ax.axvline(1 - ALPHA, color='gray', linestyle=':', alpha=0.5)\n",
    "    ax.set_title(f'{path}\\nAUC={r[\"nih_auc\"]:.3f}', fontsize=10, fontweight='bold')\n",
    "    ax.set_xlabel('Confidence (1−α)'); ax.set_ylabel('Deferral rate')\n",
    "    ax.set_xlim(0.5, 1.0); ax.set_ylim(-0.05, 1.05)\n",
    "    ax.legend(fontsize=7)\n",
    "\n",
    "axes_flat[-1].axis('off')\n",
    "plt.suptitle('Deferral Rate vs Confidence Level — Four Methods\\n'\n",
    "             'Vertical dashed line marks α=0.10 operating point',\n",
    "             fontsize=13, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-s12",
   "metadata": {},
   "source": [
    "## 12. Extended Analysis\n",
    "\n",
    "### A0. Prediction Set Collection at α = 0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-a0-collect",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALPHA_FIXED = 0.10\n",
    "detail = {}\n",
    "\n",
    "for pathology in COMMON_PATHOLOGIES:\n",
    "    k = COMMON_PATHOLOGIES.index(pathology)\n",
    "    clf_p, c_mask, n_mask, yc, yn = clfs_per_path[pathology]\n",
    "\n",
    "    Xc = X_cal[c_mask]\n",
    "    Xn = X_nih[n_mask]\n",
    "\n",
    "    # Logits\n",
    "    cal_lg        = binary_logits_from_lr(clf_p, Xc)\n",
    "    nih_lg        = binary_logits_from_lr(clf_p, Xn)\n",
    "    cal_lg_em     = corrected_binary_logits(clf_p, Xc, prior_src[k], prior_tgt_em[k])\n",
    "    nih_lg_em     = corrected_binary_logits(clf_p, Xn, prior_src[k], prior_tgt_em[k])\n",
    "    cal_lg_oracle = corrected_binary_logits(clf_p, Xc, prior_src[k], prior_tgt_oracle[k])\n",
    "    nih_lg_oracle = corrected_binary_logits(clf_p, Xn, prior_src[k], prior_tgt_oracle[k])\n",
    "\n",
    "    wc_gnn = w_cal_gnn[c_mask]\n",
    "    wn_gnn = w_nih_gnn[n_mask]\n",
    "\n",
    "    # Standard CP\n",
    "    cp_std = ConformalPredictor(penalty=0.1, kreg=1, randomized=False)\n",
    "    q_std  = cp_std.calibrate(cal_lg, yc, alpha=ALPHA_FIXED)\n",
    "    ps_std = cp_std.predict(nih_lg)\n",
    "    cal_scores_std = cp_std.cal_scores\n",
    "\n",
    "    # WCP-GNN\n",
    "    wcp_g = WeightedConformalPredictor(penalty=0.1, kreg=1, randomized=False)\n",
    "    wcp_g.calibrate(cal_lg, yc, wc_gnn)\n",
    "    ps_gnn = wcp_g.predict(nih_lg, wn_gnn, alpha=ALPHA_FIXED)\n",
    "    cal_scores_gnn = wcp_g.cal_scores_sorted   # sorted cal RAPS scores (no LSC)\n",
    "    cal_w_gnn      = wcp_g.cal_weights_sorted\n",
    "\n",
    "    # WCP-GNN + EM-LSC\n",
    "    wcp_em = WeightedConformalPredictor(penalty=0.1, kreg=1, randomized=False)\n",
    "    wcp_em.calibrate(cal_lg_em, yc, wc_gnn)\n",
    "    ps_em = wcp_em.predict(nih_lg_em, wn_gnn, alpha=ALPHA_FIXED)\n",
    "    cal_scores_em = wcp_em.cal_scores_sorted\n",
    "    cal_w_em      = wcp_em.cal_weights_sorted\n",
    "\n",
    "    # WCP-GNN + Oracle-LSC\n",
    "    wcp_oracle = WeightedConformalPredictor(penalty=0.1, kreg=1, randomized=False)\n",
    "    wcp_oracle.calibrate(cal_lg_oracle, yc, wc_gnn)\n",
    "    ps_oracle = wcp_oracle.predict(nih_lg_oracle, wn_gnn, alpha=ALPHA_FIXED)\n",
    "    cal_scores_oracle = wcp_oracle.cal_scores_sorted\n",
    "    cal_w_oracle      = wcp_oracle.cal_weights_sorted\n",
    "\n",
    "    detail[pathology] = dict(\n",
    "        ps_std=ps_std, ps_gnn=ps_gnn, ps_em=ps_em, ps_oracle=ps_oracle,\n",
    "        yn=yn, nih_lg=nih_lg, nih_lg_em=nih_lg_em, nih_lg_oracle=nih_lg_oracle,\n",
    "        cal_scores_std=cal_scores_std,\n",
    "        cal_scores_gnn=cal_scores_gnn, cal_w_gnn=cal_w_gnn,\n",
    "        cal_scores_em=cal_scores_em,   cal_w_em=cal_w_em,\n",
    "        cal_scores_oracle=cal_scores_oracle, cal_w_oracle=cal_w_oracle,\n",
    "        wc_gnn=wc_gnn, wn_gnn=wn_gnn, q_std=q_std,\n",
    "    )\n",
    "\n",
    "print(f'Prediction sets collected for {len(detail)} pathologies at α={ALPHA_FIXED}')\n",
    "print(f'\\n{\"Pathology\":<16}  {\"n_nih\":>6}  '\n",
    "      f'{\"Std |C|=0/1/2\":>18}  {\"GNN |C|=0/1/2\":>18}  '\n",
    "      f'{\"EM-LSC |C|=0/1/2\":>20}  {\"Oracle |C|=0/1/2\":>20}')\n",
    "print('-' * 110)\n",
    "for path, d in detail.items():\n",
    "    def fmtsz(ps):\n",
    "        s = ps.sum(axis=1)\n",
    "        return f'{(s==0).mean():.2f}/{(s==1).mean():.2f}/{(s==2).mean():.2f}'\n",
    "    print(f'{path:<16}  {len(d[\"yn\"]):>6}  '\n",
    "          f'{fmtsz(d[\"ps_std\"]):>18}  {fmtsz(d[\"ps_gnn\"]):>18}  '\n",
    "          f'{fmtsz(d[\"ps_em\"]):>20}  {fmtsz(d[\"ps_oracle\"]):>20}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-a1",
   "metadata": {},
   "source": [
    "### A1. Empirical Coverage Validity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_cov = 1 - ALPHA\n",
    "print(f'A1: Coverage validity at α={ALPHA}  (target ≥ {target_cov:.2f}):')\n",
    "hdr = (f\"{'Pathology':<16} | \"\n",
    "       f\"{'Std cov':>9} {'dev':>7} | \"\n",
    "       f\"{'GNN cov':>9} {'dev':>7} | \"\n",
    "       f\"{'EM-LSC cov':>11} {'dev':>7} | \"\n",
    "       f\"{'Oracle cov':>11} {'dev':>7}\")\n",
    "print(hdr); print('-' * len(hdr))\n",
    "\n",
    "under_cov = {'Std CP': 0, 'WCP-GNN': 0, 'WCP-GNN+EM': 0, 'WCP-GNN+Oracle': 0}\n",
    "\n",
    "for path in COMMON_PATHOLOGIES:\n",
    "    r = all_results[path]\n",
    "    std_c   = at_alpha(r['std_cp']).coverage_rate\n",
    "    gnn_c   = at_alpha(r['wcp_gnn']).coverage_rate\n",
    "    em_c    = at_alpha(r['wcp_gnn_em']).coverage_rate\n",
    "    orc_c   = at_alpha(r['wcp_gnn_oracle']).coverage_rate\n",
    "\n",
    "    def flag(c): return ' ✗' if c < target_cov else '  '\n",
    "    print(f'{path:<16} | '\n",
    "          f'{std_c:>9.3f} {std_c - target_cov:>+7.3f}{flag(std_c)} | '\n",
    "          f'{gnn_c:>9.3f} {gnn_c - target_cov:>+7.3f}{flag(gnn_c)} | '\n",
    "          f'{em_c:>11.3f} {em_c - target_cov:>+7.3f}{flag(em_c)} | '\n",
    "          f'{orc_c:>11.3f} {orc_c - target_cov:>+7.3f}{flag(orc_c)}')\n",
    "\n",
    "    for key, cnt_key in [\n",
    "        ('std_cp','Std CP'), ('wcp_gnn','WCP-GNN'),\n",
    "        ('wcp_gnn_em','WCP-GNN+EM'), ('wcp_gnn_oracle','WCP-GNN+Oracle')\n",
    "    ]:\n",
    "        if at_alpha(r[key]).coverage_rate < target_cov:\n",
    "            under_cov[cnt_key] += 1\n",
    "\n",
    "print(f'\\nUnder-coverage count (cov < {target_cov:.2f}) at α={ALPHA}:')\n",
    "for method, cnt in under_cov.items():\n",
    "    print(f'  {method:<20}  {cnt}/7 pathologies  '\n",
    "          f'{\"← INVALID\" if cnt > 0 else \"✓ all valid\"}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-a2",
   "metadata": {},
   "source": [
    "### A2. Prediction Set Size Breakdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_vis = [\n",
    "    ('Std CP',     'ps_std',    '#1f77b4'),\n",
    "    ('WCP-GNN',    'ps_gnn',    '#2ca02c'),\n",
    "    ('WCP+EM-LSC', 'ps_em',     '#d62728'),\n",
    "    ('WCP+Oracle', 'ps_oracle', '#9467bd'),\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(1, 4, figsize=(22, 5))\n",
    "x = np.arange(len(COMMON_PATHOLOGIES))\n",
    "\n",
    "for ax, (label, ps_key, base_col) in zip(axes, methods_vis):\n",
    "    f0 = np.array([detail[p][ps_key].sum(axis=1) == 0 for p in COMMON_PATHOLOGIES], dtype=float).mean(axis=1)\n",
    "    f1 = np.array([detail[p][ps_key].sum(axis=1) == 1 for p in COMMON_PATHOLOGIES], dtype=float).mean(axis=1)\n",
    "    f2 = np.array([detail[p][ps_key].sum(axis=1) == 2 for p in COMMON_PATHOLOGIES], dtype=float).mean(axis=1)\n",
    "    avg= np.array([detail[p][ps_key].sum(axis=1).mean() for p in COMMON_PATHOLOGIES])\n",
    "\n",
    "    ax.bar(x, f0,         color='#d62728', alpha=0.85, label='|C|=0 (empty)')\n",
    "    ax.bar(x, f1, bottom=f0,     color='#2ca02c', alpha=0.85, label='|C|=1 (singleton)')\n",
    "    ax.bar(x, f2, bottom=f0+f1, color='#ff7f0e', alpha=0.85, label='|C|=2 (full/defer)')\n",
    "\n",
    "    for xi, av in zip(x, avg):\n",
    "        ax.text(xi, 1.02, f'{av:.2f}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels([p[:9] for p in COMMON_PATHOLOGIES], rotation=35, ha='right')\n",
    "    ax.set_ylabel('Fraction of test samples')\n",
    "    ax.set_title(f'{label}  (α=0.10)', fontsize=11, fontweight='bold')\n",
    "    ax.legend(fontsize=8); ax.set_ylim(0, 1.12)\n",
    "\n",
    "plt.suptitle('A2: Prediction Set Size Distribution per Method\\n'\n",
    "             'Number above bar = average |C(X)|;  ideal = 1.0',\n",
    "             fontsize=13, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary table\n",
    "print(f'\\nA2 Summary: singleton rate (f₁) and average set size at α={ALPHA}:')\n",
    "hdr2 = (f\"{'Pathology':<16} | \"\n",
    "        f\"{'Std f1':>7} {'avg':>5} | \"\n",
    "        f\"{'GNN f1':>7} {'avg':>5} | \"\n",
    "        f\"{'EM f1':>7} {'avg':>5} | \"\n",
    "        f\"{'Oracle f1':>9} {'avg':>5}\")\n",
    "print(hdr2); print('-' * len(hdr2))\n",
    "for path in COMMON_PATHOLOGIES:\n",
    "    d = detail[path]\n",
    "    def ss(ps_key):\n",
    "        s = d[ps_key].sum(axis=1)\n",
    "        return f'{(s==1).mean():>7.3f} {s.mean():>5.2f}'\n",
    "    print(f'{path:<16} | {ss(\"ps_std\")} | {ss(\"ps_gnn\")} | {ss(\"ps_em\")} | {ss(\"ps_oracle\"):>9}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-a3",
   "metadata": {},
   "source": [
    "### A3. Singleton Error Rate — FNR / FPR\n",
    "\n",
    "**Core question**: Does LSC reduce the dangerously high FNR on singleton decisions?\n",
    "\n",
    "Recall: with q̂ = 1.0 (binary RAPS), every singleton `{k}` satisfies\n",
    "\"model's top prediction = k\". So singleton FNR = P(top prediction = 0 | true label = 1,\n",
    "sample is singleton) = fraction of true positives for which the model ranks class 1 second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "singleton_rows = []\n",
    "\n",
    "for path in COMMON_PATHOLOGIES:\n",
    "    d  = detail[path]\n",
    "    yn = d['yn']\n",
    "    row = {'Pathology': path, 'n_pos': int(yn.sum())}\n",
    "\n",
    "    for label, ps_key in [('Std CP','ps_std'), ('WCP-GNN','ps_gnn'),\n",
    "                           ('WCP+EM','ps_em'),  ('WCP+Oracle','ps_oracle')]:\n",
    "        ps   = d[ps_key]\n",
    "        sizes = ps.sum(axis=1)\n",
    "        singleton_idx = np.where(sizes == 1)[0]\n",
    "        n_s = len(singleton_idx)\n",
    "\n",
    "        if n_s == 0:\n",
    "            row[f'{label}_n_pct']  = '0 (0%)'\n",
    "            row[f'{label}_FNR']    = np.nan\n",
    "            row[f'{label}_FPR']    = np.nan\n",
    "            continue\n",
    "\n",
    "        preds_s = ps[singleton_idx].argmax(axis=1)   # top prediction\n",
    "        y_s     = yn[singleton_idx]\n",
    "        pos     = y_s == 1;  neg = y_s == 0\n",
    "\n",
    "        fnr = float((preds_s[pos] == 0).mean()) if pos.sum() > 0 else np.nan\n",
    "        fpr = float((preds_s[neg] == 1).mean()) if neg.sum() > 0 else np.nan\n",
    "\n",
    "        row[f'{label}_n_pct'] = f'{n_s} ({100*n_s/len(yn):.0f}%)'\n",
    "        row[f'{label}_FNR']   = round(fnr, 4)\n",
    "        row[f'{label}_FPR']   = round(fpr, 4)\n",
    "\n",
    "    singleton_rows.append(row)\n",
    "\n",
    "df_single = pd.DataFrame(singleton_rows).set_index('Pathology')\n",
    "\n",
    "print(f'A3: Singleton Error Rate at α={ALPHA}')\n",
    "print('=' * 100)\n",
    "hdr3 = (f\"{'Pathology':<16} {'n_pos':>6} | \"\n",
    "        f\"{'GNN n_single':>14} {'FNR':>6} {'FPR':>6} | \"\n",
    "        f\"{'EM-LSC n_single':>16} {'FNR':>6} {'FPR':>6} | \"\n",
    "        f\"{'Oracle n_single':>16} {'FNR':>6} {'FPR':>6}\")\n",
    "print(hdr3); print('-' * len(hdr3))\n",
    "\n",
    "for path in COMMON_PATHOLOGIES:\n",
    "    r = df_single.loc[path]\n",
    "    def fmt(m):\n",
    "        n   = str(r.get(f'{m}_n_pct', '—'))\n",
    "        fnr = r.get(f'{m}_FNR', np.nan)\n",
    "        fpr = r.get(f'{m}_FPR', np.nan)\n",
    "        fnr_s = f'{fnr:.3f}' if not np.isnan(fnr) else '  n/a'\n",
    "        fpr_s = f'{fpr:.3f}' if not np.isnan(fpr) else '  n/a'\n",
    "        return f'{n:>14} {fnr_s:>6} {fpr_s:>6}'\n",
    "    print(f'{path:<16} {r[\"n_pos\"]:>6} | {fmt(\"WCP-GNN\")} | {fmt(\"WCP+EM\")} | {fmt(\"WCP+Oracle\")}')\n",
    "\n",
    "# FNR/FPR bar plot\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "x = np.arange(len(COMMON_PATHOLOGIES))\n",
    "width = 0.25\n",
    "\n",
    "vis_methods = [('WCP-GNN','#2ca02c'), ('WCP+EM','#d62728'), ('WCP+Oracle','#9467bd')]\n",
    "\n",
    "for ax, metric in zip(axes, ['FNR', 'FPR']):\n",
    "    for m_i, (method, col) in enumerate(vis_methods):\n",
    "        vals = [float(df_single.loc[p].get(f'{method}_{metric}', np.nan))\n",
    "                for p in COMMON_PATHOLOGIES]\n",
    "        vals = [v if not np.isnan(v) else 0 for v in vals]\n",
    "        ax.bar(x + (m_i - 1) * width, vals, width, label=method, color=col, alpha=0.8)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(COMMON_PATHOLOGIES, rotation=30, ha='right')\n",
    "    ax.set_ylabel(metric)\n",
    "    lbl = ('False Negative Rate (missed diagnoses)' if metric == 'FNR'\n",
    "           else 'False Positive Rate (false alarms)')\n",
    "    ax.set_title(f'Singleton {metric}: {lbl}\\n(non-deferred samples only, α=0.10)')\n",
    "    ax.legend(fontsize=9); ax.set_ylim(0, 1.05)\n",
    "\n",
    "plt.suptitle('A3: Singleton Error Rate — Impact of Label Shift Correction on FNR & FPR',\n",
    "             fontsize=13, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-a4",
   "metadata": {},
   "source": [
    "### A4. q̂ Stability — Weighted CDF of Calibration RAPS Scores\n",
    "\n",
    "LSC shifts the distribution of calibration RAPS scores because it recalibrates\n",
    "the model probabilities.  Under lower target prevalence:\n",
    "- True-negative calibration samples → model becomes MORE confident negative → RAPS score drops\n",
    "- True-positive calibration samples → model becomes LESS confident positive → RAPS score rises\n",
    "\n",
    "If NIH-like calibration samples are predominantly negatives, the weighted quantile\n",
    "q̂ drops further under LSC, potentially creating more singletons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "focus_paths = ['Cardiomegaly', 'Pneumothorax', 'Effusion', 'Atelectasis']\n",
    "fig, axes = plt.subplots(len(focus_paths), 3, figsize=(18, 5 * len(focus_paths)))\n",
    "\n",
    "def plot_weighted_cdf(ax, scores, weights, label, color, alpha_line=ALPHA, title=''):\n",
    "    \"\"\"Plot weighted vs unweighted empirical CDF and mark q̂.\"\"\"\n",
    "    sort_idx = np.argsort(scores)\n",
    "    s_sorted = scores[sort_idx]\n",
    "    w_sorted = weights[sort_idx]\n",
    "    w_norm   = w_sorted / w_sorted.sum()\n",
    "    cum_w    = np.cumsum(w_norm)\n",
    "    cum_uw   = np.arange(1, len(s_sorted) + 1) / len(s_sorted)\n",
    "\n",
    "    ax.step(s_sorted, cum_uw, where='post', color='#1f77b4', lw=1.5, alpha=0.7, label='Unweighted CDF')\n",
    "    ax.step(s_sorted, cum_w,  where='post', color=color,     lw=2.0, alpha=0.9, label=f'Weighted CDF ({label})')\n",
    "\n",
    "    target  = 1 - alpha_line\n",
    "    idx_q   = min(int(np.searchsorted(cum_w, target, side='left')), len(s_sorted) - 1)\n",
    "    q_hat_w = s_sorted[idx_q]\n",
    "\n",
    "    ax.axvline(q_hat_w, color=color, linestyle='--', lw=1.8, label=f'q̂ weighted = {q_hat_w:.3f}')\n",
    "    ax.axhline(target, color='gray', linestyle=':', lw=1.0, alpha=0.5, label=f'1−α = {target:.2f}')\n",
    "\n",
    "    ess_pct = float(weights.sum()**2 / (weights**2).sum()) / len(weights) * 100\n",
    "    ax.set_title(f'{title}\\n{label} | ESS={ess_pct:.1f}% | q̂={q_hat_w:.3f}',\n",
    "                 fontsize=9, fontweight='bold')\n",
    "    ax.set_xlabel('RAPS score'); ax.set_ylabel('Cumulative probability')\n",
    "    ax.legend(fontsize=7)\n",
    "    ax.set_xlim(max(-0.05, float(s_sorted.min()) - 0.05),\n",
    "                min(float(s_sorted.max()) + 0.05, 1.25))\n",
    "\n",
    "for row_i, path in enumerate(focus_paths):\n",
    "    d = detail[path]\n",
    "    plot_weighted_cdf(axes[row_i, 0], d['cal_scores_gnn'],    d['cal_w_gnn'],    'GNN (no LSC)',   '#2ca02c', title=path)\n",
    "    plot_weighted_cdf(axes[row_i, 1], d['cal_scores_em'],     d['cal_w_em'],     'GNN+EM-LSC',    '#d62728', title=path)\n",
    "    plot_weighted_cdf(axes[row_i, 2], d['cal_scores_oracle'], d['cal_w_oracle'], 'GNN+Oracle-LSC','#9467bd', title=path)\n",
    "\n",
    "plt.suptitle('A4: Weighted CDF of Calibration RAPS Scores\\n'\n",
    "             'Columns: no LSC | EM-LSC | Oracle-LSC;  Rows: focus pathologies',\n",
    "             fontsize=12, fontweight='bold', y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# q̂ table (using median test weight as representative)\n",
    "def scalar_qhat(scores_sorted, cal_w, test_weight, alpha):\n",
    "    all_w = np.append(cal_w, test_weight)\n",
    "    p     = all_w / all_w.sum()\n",
    "    cum_p = np.cumsum(p[:-1])\n",
    "    reached = cum_p >= (1 - alpha)\n",
    "    if not reached.any(): return float('inf')\n",
    "    return float(scores_sorted[int(np.argmax(reached))])\n",
    "\n",
    "print(f'\\nq̂ at median test weight (α={ALPHA}):')\n",
    "hdr4 = f\"{'Pathology':<16} {'Std q̂':>8} {'GNN q̂':>8} {'EM-LSC q̂':>11} {'Oracle q̂':>11}\"\n",
    "print(hdr4); print('-'*len(hdr4))\n",
    "for path in COMMON_PATHOLOGIES:\n",
    "    d   = detail[path]\n",
    "    med_w = float(np.median(d['wn_gnn']))\n",
    "    q_gnn = scalar_qhat(d['cal_scores_gnn'],    d['cal_w_gnn'],    med_w, ALPHA)\n",
    "    q_em  = scalar_qhat(d['cal_scores_em'],      d['cal_w_em'],     med_w, ALPHA)\n",
    "    q_orc = scalar_qhat(d['cal_scores_oracle'],  d['cal_w_oracle'], med_w, ALPHA)\n",
    "    fmt = lambda q: f'{q:.3f}' if q != float('inf') else '  ∞'\n",
    "    print(f'{path:<16} {d[\"q_std\"]:>8.3f} {fmt(q_gnn):>8} {fmt(q_em):>11} {fmt(q_orc):>11}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-s13",
   "metadata": {},
   "source": [
    "### A5. FNR Breakdown: Positives in Singleton Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Breakdown: for singleton positive samples, how many are predicted correctly?\n",
    "print('A5: Positive samples in singleton set and their predictions')\n",
    "print('(key: with q̂=1.0, singleton prediction = model top-ranked class)')\n",
    "print('='*100)\n",
    "\n",
    "for path in COMMON_PATHOLOGIES:\n",
    "    d   = detail[path]\n",
    "    yn  = d['yn']\n",
    "    print(f'\\n{path}  (n_pos={yn.sum()}, n_nih={len(yn)})')\n",
    "    hdr5 = (f\"  {'Method':<18} {'n_single':>9} {'n_single_pos':>13} \"\n",
    "            f\"{'n_pos_correct':>15} {'FNR':>7} {'FPR':>7}\")\n",
    "    print(hdr5); print('  ' + '-'*(len(hdr5)-2))\n",
    "\n",
    "    for method, ps_key in [('WCP-GNN','ps_gnn'), ('WCP+EM-LSC','ps_em'), ('WCP+Oracle','ps_oracle')]:\n",
    "        ps    = d[ps_key]\n",
    "        sizes = ps.sum(axis=1)\n",
    "        sidx  = np.where(sizes == 1)[0]\n",
    "        n_s   = len(sidx)\n",
    "        if n_s == 0:\n",
    "            print(f'  {method:<18} {0:>9}'); continue\n",
    "\n",
    "        preds = ps[sidx].argmax(axis=1)\n",
    "        y_s   = yn[sidx]\n",
    "        pos   = y_s == 1;  neg = y_s == 0\n",
    "        n_pos_s   = int(pos.sum())\n",
    "        n_pos_c   = int((preds[pos] == 1).sum()) if n_pos_s > 0 else 0\n",
    "        fnr = 1 - n_pos_c / n_pos_s if n_pos_s > 0 else np.nan\n",
    "        fpr = float((preds[neg] == 1).mean()) if neg.sum() > 0 else np.nan\n",
    "        print(f'  {method:<18} {n_s:>9} {n_pos_s:>13} {n_pos_c:>15} '\n",
    "              f'{fnr:>7.3f}' + f'{fpr:>8.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-s14",
   "metadata": {},
   "source": [
    "## 13. Comparison with gnn_dre_wcp_report.md Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-compare",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference GNN-DRE results from gnn_dre_wcp_report.md (Table 5, α=0.10)\n",
    "REF_GNN = {\n",
    "    'Atelectasis':   dict(defer=0.952, cov=0.994, fnr=0.784, fpr=0.092, f1=0.05, avg=1.95),\n",
    "    'Cardiomegaly':  dict(defer=0.038, cov=0.887, fnr=0.779, fpr=0.059, f1=0.96, avg=0.96),\n",
    "    'Consolidation': dict(defer=0.120, cov=0.849, fnr=0.861, fpr=0.023, f1=0.88, avg=0.88),\n",
    "    'Edema':         dict(defer=0.956, cov=0.996, fnr=0.500, fpr=0.096, f1=0.04, avg=1.96),\n",
    "    'Effusion':      dict(defer=0.230, cov=0.923, fnr=0.527, fpr=0.082, f1=0.77, avg=1.23),\n",
    "    'Pneumonia':     dict(defer=0.042, cov=0.883, fnr=0.872, fpr=0.073, f1=0.96, avg=0.96),\n",
    "    'Pneumothorax':  dict(defer=0.087, cov=0.901, fnr=0.992, fpr=0.005, f1=0.91, avg=0.91),\n",
    "}\n",
    "\n",
    "cmp_rows = []\n",
    "for path in COMMON_PATHOLOGIES:\n",
    "    ref = REF_GNN[path]\n",
    "    d   = detail[path]\n",
    "    r   = all_results[path]\n",
    "    em  = at_alpha(r['wcp_gnn_em'])\n",
    "\n",
    "    # Singleton FNR for EM-LSC\n",
    "    ps   = d['ps_em']; sizes = ps.sum(axis=1)\n",
    "    sidx = np.where(sizes == 1)[0]\n",
    "    yn   = d['yn']\n",
    "    if len(sidx) > 0:\n",
    "        preds = ps[sidx].argmax(axis=1); y_s = yn[sidx]\n",
    "        pos = y_s == 1; neg = y_s == 0\n",
    "        fnr_em = float((preds[pos] == 0).mean()) if pos.sum() > 0 else np.nan\n",
    "        fpr_em = float((preds[neg] == 1).mean()) if neg.sum() > 0 else np.nan\n",
    "        f1_em  = float((sizes==1).mean())\n",
    "    else:\n",
    "        fnr_em = fpr_em = f1_em = np.nan\n",
    "\n",
    "    cmp_rows.append({\n",
    "        'Pathology':         path,\n",
    "        'Ref-GNN Defer':     f\"{ref['defer']:.3f}\",\n",
    "        'EM-LSC Defer':      f\"{em.deferral_rate:.3f}\",\n",
    "        'Δ Defer':           f\"{em.deferral_rate - ref['defer']:+.3f}\",\n",
    "        'Ref-GNN Cov':       f\"{ref['cov']:.3f}\",\n",
    "        'EM-LSC Cov':        f\"{em.coverage_rate:.3f}\",\n",
    "        'Ref-GNN FNR':       f\"{ref['fnr']:.3f}\",\n",
    "        'EM-LSC FNR':        f\"{fnr_em:.3f}\" if not np.isnan(fnr_em) else 'n/a',\n",
    "        'Δ FNR':             f\"{fnr_em - ref['fnr']:+.3f}\" if not np.isnan(fnr_em) else 'n/a',\n",
    "        'Ref-GNN f₁':        f\"{ref['f1']:.3f}\",\n",
    "        'EM-LSC f₁':         f\"{f1_em:.3f}\" if not np.isnan(f1_em) else 'n/a',\n",
    "    })\n",
    "\n",
    "df_cmp = pd.DataFrame(cmp_rows)\n",
    "print('Comparison: WCP-GNN (baseline) vs WCP-GNN+EM-LSC (new)  — α=0.10')\n",
    "print('='*120)\n",
    "print(df_cmp.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md-s15",
   "metadata": {},
   "source": [
    "## 14. Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-final",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 75)\n",
    "print(f'GNN-DRE + EM-LSC Summary  (α={ALPHA})')\n",
    "print('=' * 75)\n",
    "\n",
    "print('\\nEstimated vs True NIH Prevalences:')\n",
    "for k, path in enumerate(COMMON_PATHOLOGIES):\n",
    "    print(f'  {path:<16}  src={prior_src[k]:.4f}  oracle={prior_tgt_oracle[k]:.4f}  '\n",
    "          f'EM={prior_tgt_em[k]:.4f}  '\n",
    "          f'err={abs(prior_tgt_em[k]-prior_tgt_oracle[k])*100:+.2f}pp')\n",
    "\n",
    "print('\\nMean results at α=0.10:')\n",
    "for label, key in [('Std CP','std_cp'), ('WCP-GNN','wcp_gnn'),\n",
    "                    ('WCP+EM-LSC','wcp_gnn_em'), ('WCP+Oracle','wcp_gnn_oracle')]:\n",
    "    mean_d = np.mean([at_alpha(all_results[p][key]).deferral_rate for p in COMMON_PATHOLOGIES])\n",
    "    mean_c = np.mean([at_alpha(all_results[p][key]).coverage_rate  for p in COMMON_PATHOLOGIES])\n",
    "    print(f'  {label:<20}  defer={mean_d:.3f}   coverage={mean_c:.3f}')\n",
    "\n",
    "print('\\nKey pathology outcomes (EM-LSC vs baseline GNN):')\n",
    "for path in COMMON_PATHOLOGIES:\n",
    "    gnn_d  = at_alpha(all_results[path]['wcp_gnn']).deferral_rate\n",
    "    em_d   = at_alpha(all_results[path]['wcp_gnn_em']).deferral_rate\n",
    "    em_cov = at_alpha(all_results[path]['wcp_gnn_em']).coverage_rate\n",
    "    arrow  = '↓' if em_d < gnn_d - 0.01 else ('↑' if em_d > gnn_d + 0.01 else '≈')\n",
    "    print(f'  {path:<16}  GNN defer={gnn_d:.3f}  EM-LSC defer={em_d:.3f}  '\n",
    "          f'({arrow}{abs(em_d-gnn_d):.3f})  cov={em_cov:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wcp-l2d",
   "language": "python",
   "name": "wcp-l2d"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
